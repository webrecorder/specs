<html>
  <head>
  <title>Web Archive Collection Zipped (WACZ)</title>
  <script src="https://www.w3.org/Tools/respec/respec-w3c" class="remove" defer ></script>
  <script class="remove">
    var respecConfig = {
      specStatus: "unofficial",
      publishDate: "2021-11-04",
      thisVersion: "https://webrecorder.github.io/wacz-format/1.2.0/",
      latestVersion: "https://webrecorder.github.io/wacz-format/latest/",
      shortName: "wacz-format",
      lint: {
	// turn off w3c-specific linting
	"privsec-section": false,
	"no-http-props": false,
	"no-headingless-sections": false
      },
      includePermalinks: true,
      editors: [
	{
	  name: "Ilya Kreymer",
	  url: "https://www.linkedin.com/in/ilya-kreymer-55110093/",
	  company: "Webrecorder",
	  companyURL: "https://webrecorder.net/"
	},
        {
          name: "Ed Summers",
          url: "https://www.linkedin.com/in/esummers/",
          company: "Stanford University",
          companyURL: "https://stanford.edu"
        }
      ],
      group: {
        name: "WACZ Editors",
        url: "https://webrecorder.net"
      },
      wgPublicList: "",
      otherLinks: [
	{
	  key: "Additional Documents",
	  data: [
	    {
	      value: "Specification",
	      href: "https://webrecorder.github.io/wacz-spec/latest/",
	    }
	  ]
	},
	{
	  key: "Previous version",
	  data: [
	      {
		  value: "1.1.1",
		  href: "https://github.com/webrecorder/wacz-spec/tree/4fb485e018f45996bfb1d992f937b67f3d6c79a9"
	      }
	  ]
      	},
	{
	  key: "Repository",
	  data: [
	    {
	      value: "Github",
	      href: "https://github.com/webrecorder/wacz-format"
	    },
	    {
	      value: "Issues",
	      href: "https://github.com/webrecorder/wacz-format/issues"
	    },
	    {
	      value: "Commits",
	      href: "https://github.com/webrecorder/wacz-format/commits"
	    },
	    {
	      value: "Use Cases",
	      href: "https://github.com/webrecorder/wacz-spec/labels/use-case"
	    }
	  ]
      	}
      ],
      maxTocLevel: 3,
      logos: [
	{
	  src: "https://webrecorder.github.io/wacz-spec/1.2.0/images/wacz.png",
	  alt: "WACZ Logo",
          height: 100
      	}
      ],
      localBiblio: {
      }
    };
  </script>
  </head>

  <body>

    <p id="sotd">
    This document is working draft/proposal for a directory structure + ZIP
    format specification for sharing and distributing web archives. ZIP files
    using this format can be referred to as WACZ (Web Archive Collection
    Zipped). Feedback on this proposal is strongly encouraged!. Please open
    <a href="https://github.com/webrecorder/wacz-spec/issues/">GitHub issues</a>
    with any thoughts/suggestions/comments.
    </p>

    <section id="abstract">
    WACZ is a packaging format that allows web archives to become a first class
    media type on the web. It achieves this by addressing two key social and
    technical issues. WACZ provides an interoperable way to share web archive
    <em>collections</em>, including any data necessary to make web archives
    useful for people to understand what they contain. In addition WACZ has been
    designed to provide an efficient way of loading *discrete amounts of data*
    from a remotely hosted web archive on static storage, without requiring the
    entire collection to be retrieved. 
    </section>

    <section id="conformance" data-format="markdown">

# Conformance

**TODO: add details about what is normative and what is non-normative in the
specification.**

The key words MAY, MUST, MUST NOT, SHOULD, and SHOULD NOT in this document are
to be interpreted as described in BCP 14 [RFC2119] [RFC8174] when, and only
when, they appear in all capitals, as shown here. 

    </section>

    <section data-format="markdown">

# Terminology

**TODO: Provide a list of term definitions that are used in the specification.**

    </section>

    <section data-format="markdown">

# Introduction

This document is working draft/proposal for a directory structure + ZIP format specification for sharing and distributing web archives. ZIP files using this format can be referred to as WACZ (Web Archive Collection Zipped).

Feedback on this proposal is *strongly encouraged!*.

Please open GitHub issues with any thoughts/suggestions/comments.

## Motivation

The goal of this specification is to provide a portable format for web archives, to address key social and technical issues:

- Social: to provide an interoperable way to share web archive *collections*, including any data necessary to make web archives useful to humans.
- Technical: to provide an efficient way to load *small amounts of data* from a remotely hosted web archive on static storage, without downloading the entire collection.

### Social: Making web archives more human friendly

To make sense and use a web archive, it is necessary to have more than just the
raw HTTP request/response data, yet no standardized format exists to include all
the data that is needed.

In particular, a web archive collection should have:
- A random-access index of all raw data (preferably accessible with minimal seek)
- A set of pages, entry point URLs from which users should browse the web archive.
- Other user-defined, editable metadata about the web archive collection (title, description, etc...)

All of this data can be bundled together into a single file, using the standard ZIP format.

### Technical: Lowering the barrier to hosting large web archives

Hosting web archives currently requires complex server infrastructure, a 'wayback machine' to serve data in a way that can be viewed in the browser.

Tools like `wabac.js` provide a way to render the data directly in the browser, if it can be accessed efficiently.

The WACZ format presents a storage approach optimized for efficient random-access to large amounts of web archive data, allowing the client to load only
what is needed by seeking into a larger file (via HTTP range requests or other random access) and loading only what is needed for each page.
This is done by leveraging the ZIP format's built-in index, inclusion of an efficient web archive index (CDX or compressed CDX) along with the raw WARC data.

The spec is not designed to replace any other format, but to set up a convention-based format to bundle all necessary data together,
following a certain directory and naming convention, into a standard ZIP (or ZIP64) file.

## Existing Tools 

The [py-wacz](https://github.com/webrecorder/py-wacz) repository contains a
reference implementation for creating WACZ files from existing WARC files, and
validating them.

Parts of the specification are also implemented and in use by
[wabac.js](https://github.com/webrecorder/wabac.js) and
[ReplayWeb.page](https://replayweb.page).


    </section>

    <section data-format="markdown">

# WACZ Object 

The spec currently consists of the following:

1) A [frictionless data](https://frictionlessdata.io/) `datapackage.json` file for recording metadata.
2) A extensible directory and naming convention for web archive data
3) A specification for bundling the directory layout in a ZIP file.

The documentation is split into what is currently supported in [wabac.js](https://github.com/webrecorder/wabac.js) as stable,
experimental ideas, and possible future extensions.

See the [CHANGES.md](CHANGES.md) file for a list of changes to WACZ spec and py-wacz tool.


## Directory Layout

The spec is to designate a mostly flat directory structure which can contain different types of web archive collection data while conforming to the frictionless data standards.
Currently supported:

```
- archive/
- indexes/
- pages/
- datapackage.json
- datapackage-digest.json
```

## Directories and Files

### archive/

The `archive` directory can contain raw web archive data.

Currently supported formats:
- WARC (.warc, .warc.gz)

### indexes/

**TODO: standardize on CDXJ and decide whether to specify it here or in a
separate document.**

 The `indexes` directory should include various indexes into the raw data stored in `archive/`

 Currently possible index formats include:
 - CDX (.cdx, .cdxj) for raw text-based binary sorted indices
 - Compressed CDX (.cdx.gz and .idx) indices

 **TODO: require CDXJ provide specification here, or refer to later section?**

### pages.jsonl

The `pages/pages.jsonl` file is a list of 'Page' objects as line-oriented JSON, 
each containing at least the following fields:

**TODO: reference JSONL definition or define in Terminology section?**

- `url` - a valid URL (or URI/URN?)
- `ts` - a valid ISO 8601 Date string
- `title` - any string or omitted
- `id` - any string or omitted.
- `text` - an optional extraction of the text of the page,
- `size` - an optional number of bytes for all the page resources

Ex:
```jsonl
{"format": "json-pages-1.0", "id": "pages", "title": "All Pages"}
{"id": "1db0ef709a", "url": "https://www.example.com/page", "ts": "2020-10-07T21:22:36Z", "title": "Example Domain"}
{"id": "12304e6ba9", "url": "https://www.example.com/another", "ts": "2020-10-07T21:23:36Z", "title": "Another Page"}
```

Other `.jsonl` files can optionally be added on using the same format in the `pages/` directory.

For example, py-wacz supports specifying an 'extra' pages list, loaded from `extraPages.jsonl`.

A common use case is to include only the main pages in the `pages.jsonl`, while including additional pages, such as those discovered automatically
via a crawl in an `extraPages.jsonl`.

### datapackage.json

The `datapackage.json` file serves as the manifest for the web archive and is compliant with the Frictionless [Data Package Specification](https://specs.frictionlessdata.io/data-package/)

The file contains the following keys:

- `profile`: Set to `data-package` in accordance with the Frictionless Data Package spec.

- `resources` is a list containing the contents of the WACZ, in accordance with the Frictionless Data Package spec.

  Ex:
   ```
    "resources": [
       {
         "name": "pages.jsonl",
         "path": "pages/pages.jsonl",
         "hash": "sha256:8a7fc0d302700bed02294404a627ddbbf0e35487565b1c6181c729dff8d2fff6",
         "bytes": 75
       },
       {
         "name": "data.warc",
         "path": "archive/data.warc",
         "hash": "sha256:0e7101316ba5d4b66f86a371ee615fbd20f9d3f32d32563ed2c829db062f7714",
         "bytes": 11469796
       },
       ...
   ]
   ```

WACZ data packages can also include optional data package fields, in particular:

- `title`: Can contain title for this collection.

- `description`: Can contain description for this collection.

- `created`: ISO date string for when the WACZ file was created.

- `modified`: ISO date tring for when the WACZ file was last modified.

The following fields are not part of the standard data package specification and are additional fields used with WACZ:

- `wacz_version`: Should be set to `1.0.1` (or current version of WACZ). This field is required to identify the package as a WACZ.

- `mainPageURL`: An optional URL of the main or starting page in the collection,
if any, to be used for initial replay.

- `mainPageDate`: An optional ISO-formatted date of the main or starting page in the collection, if any, to be used for initial replay. Specified only if `mainPageURL` is specified.

- "software": A description of what software was used to create the WACZ file

### datapackage-digest.json 

With WACZ 1.1, there is now also support for a special *datapackage-digest.json*, which makes it possible to verify the *datapackage.json* manifest
with a hash, and an optional signature, and thus for the entire contents of the WACZ.

The `hash` and `path` keys are required, while `signature` and `publicKey` are optional.

**TODO: align with current archiveweb.page implementation?**

Ex:
  ```json
  {
    "hash": "sha256:...",
    "path": "datapackage.json",
    "signedData": {
    "signature": "...",
    "publicKey": "..."
  }
  ```

## Record Digests

With WACZ 1.1, index entries for each individual WARC record in the index (CDX) includes a digest of the WARC record.

When a compressed CDX with a secondary index is used, each entry in the secondary index also includes a digest field.

This makes it possible to also verify each URL as it is loaded via random access, without downloading the entire WACZ file.

## Custom Derivatives

**TODO: clearly describe how new directories may be added and impact on
WACZ validators.**

Other derived data, such as screenshots, could be placed into a general-purpose
`derivatives/` directory.

Additional ideas for standardization and possible directory formats:
- derivatives
- search indexes
- WAT / WET files
- specific metadata formats?

Perhaps extension need not be specified explicitly, as others can add directories as needed.
*Feedback wanted on this section, see https://github.com/webrecorder/web-archive-collection-format/issues/1*

Other possible ideas were suggested in this issue: https://github.com/webrecorder/pywb/issues/319

## Alternatives to WARC

**TODO: consider simplifying specification by requiring WARC?**

It is possible that other formats, such as HAR, Web Bundle, ZIM be supported
in the `archive/` directory. (See Appendix for these formats).


    </section>

    <section data-format="markdown">

# CDXJ

**TODO: Define the CDXJ format here?** 

    </section>

    <section data-format="markdown">

## Zip Format

The entire directory structure can be stored in a standard ZIP or ZIP64 file.

The ZIP format is useful as a primary packaging of all the different formats.


### Zip Compression

Already compressed files should not be compressed again to allow for random access.

- All `archive/` files should be stored in ZIP with 'STORE' mode.
- All `index/*.cdx.gz` files should be stored in ZIP with 'STORE' mode.
- All files (`*.jsonl`, `*.json`, `*.idx`, `*.cdx`, `*.cdxj`) can be stored in the ZIP with either 'DEFLATE' or 'STORE' mode.

### Zip Format File Extension

A ZIP file that follows this Web Archive Collection format spec should use the extension `.wacz`.

Such a file can be referred to as a WACZ file or a WACZ.

    </section>

    <section data-format="markdown">

# Appendices

## Appendix A: Use Case: Random-Access to Web Archives in ZIP

The web archive collection format stored in a ZIP file allows for efficient random access to even very large web archives (10GB+, 100GB+, etc...). This allows for loading web archive from static storage on-demand.

The approach works as follows. Given a ZIP file, a client can quickly:
```
1) Read all entries to determine the contents of the ZIP file via random access
2) Load manifest from `datapackage.json`
3) Load list of pages from `pages.jsonl`, if any
```

To lookup a given URL, such as from the page or page list:
```
1) Read the full CDX from ZIP, or read secondary secondary index (IDX)
2) Binary search index
  2a) If using compressed CDX, read compressed CDX chunk in CDX.GZ file in ZIP.
3) If index match found, get offset/length/location in WARC
4) Read compressed WARC chunk in ZIP
```

This approach is being used by https://replayweb.page/.

The implementation is in https://github.com/webrecorder/wabac.js/blob/develop/src/ziparchive.js

and is based on: https://github.com/Rob--W/zipinfo.js/blob/master/zipinfo.js

## Appendix B: Formats Referenced

This spec refers to the following formats, which could be packaged inside a Web Archive Collection structure.
Some of the formats serve similar functions, but require custom serialization and are not extensible with custom metadata.

### WARC

The WARC format is a well established standard for storing raw web archive data.

The WARC is a raw data format only, and does not have an index, or a standardized way to store entry points,
or metadata about a web archive collection.

More Info: https://iipc.github.io/warc-specifications/specifications/warc-format/warc-1.1/

### CDX

CDX is a plain-text, binary sorted indexing format used in web archives. CDXJ is a JSON-based
variation of CDX.

More Info: https://pywb.readthedocs.io/en/latest/manual/indexing.html#index-formats for more info.

Starting with WACZ 1.1, it is possible to include a `recordDigest` in each CDX entry to specify the hash/digest of each full WARC record.

### Compressed CDX / "ZipNum"

The Compressed CDX format uses gzip compression on top of the plain-text CDX, and a secondary
index to search the compressed index. This allows the CDX index to scale to considerably larger datasets.
This index format is in use by Internet Archive's Wayback Machine and CommonCrawl.

Starting with WACZ 1.1, the index entry for each compressed CDX block also includes a `digest` field indicating the hash/digest of each block.

More Info: https://pywb.readthedocs.io/en/latest/manual/indexing.html#zipnum-sharded-index)

### HAR

The HAR format is supported by default in the DevTools of major browsers. HAR is intended for page-level archives
and is centered around page loading page metrics and browser telemetry. As a JSON-based serialization format,
it may be difficult to use for large web archiving.

HAR does include a list of entry points/pages as well as the raw resources.

More info: http://www.softwareishard.com/blog/har-12-spec/

### Web Pack/Web Bundle

The web bundle/web packaging spec attempts to solve some similar issues. Web Bundles use CBOR for serialization of HTTP request/responses, and also include an index. However, it can not be used to store existing web archive (WARC) data.

More Info: https://wicg.github.io/webpackage/draft-yasskin-wpack-bundled-exchanges.html

### ZIM

The ZIM format stores compressed files, page data and page metadata in a custom format suitable for random access loading.
The format also addresses some of the same issues raised here, but can not be used to store existing web archive data.

More Info: https://openzim.org/wiki/ZIM_file_format
    </section>

  </body>

</html>
